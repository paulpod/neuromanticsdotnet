---
title: Music, part 3
date: 2025-12-18 11:23:23
tags: Music
---

I have become far too [distracted documenting my journey]
(https://neuromantics.net/2025/11/18/music-part2/) towards some ideas, so let's park that for now and create some designs of a future music player.

## What is the minimum?

OK, so the actual minimum is no visuals, do it all by ear - match the beats of the intro to track two to already playing track one, and mix across. Low tech, high skill. DJ with decks and a simple mixer.

In our post-rekordbox, visual waveform world though? Minimum would be something like track one, with some sort of beat and bar indicator, playing and defining the playhead - the point in time of *now*. 

[![Rekordbox waveforms ](/images/matching-up.png)](/images/matching-up.png)

Then, a second track being brought in, with a matching visual of these beats, allowing the player to do the matching. As the second track is brought alongside the first, a high pass filter brings in the lower frequencies, and like some magnetic blocks, they *click together* perfectly.

Maybe a little bit like this:

{% raw %}
<video controls playsinline width="100%">
	<source src="/images/matching-up.mp4" type='video/mp4' />
	
	Sorry, your browser doesn't support embedded videos.
</video>
{% endraw %}

## More visual assistance

Beat markers are all very well, and for this let's imagine that tempo matching is automatic and also uncontroversial. Seeing ahead is really helpful, even when you know the tunes pretty well - seeing phrases coming up, markers you (or an automagic system) has put into place is useful.

The DJ software world uses variations on waveforms - these are the standard spikey horizonatl line in three colour ways. RGB is frequency related, packs a lot of information into that, the 3 band as High/Mid/Low seems more directly useful (if nowhere near as pretty).

[![Rekordbox waveforms ](/images/rekordbox-waveforms.png)](/images/rekordbox-waveforms.png)

## Graphical notation

Solid options, but what other visual elements might convey useful, structural information? Especially combined with the latest AI powered tools of dynamic stems (stripping multiple tracks out of one recording - eg. vocal, bass, drums, melody)? Decoding those stems into the notes might be useful - this might take us into [graphic notation territory](https://davidhall.io/visualising-music-graphic-scores/).

[![Ambient 1 music for airport cover, notation ](/images/alternative-notation-example-by-eno.png)](/images/alternative-notation-example-by-eno.png)

[![Ambient 1 music for airport cover, notation ](/images/alternative-notation-examples.png)](/images/alternative-notation-examples.png)

1. Cover Ambient 1 music for airport, Brian Eno
2. Actually a [sleep pattern, Jonathan Peterson](https://www.behance.net/gallery/24180505/Sleep-Pattern-C)
3. *I think* from [Diana Lange processing experiments](https://openprocessing.org/user/5969/#sketches) [also on Flickr](https://www.flickr.com/photos/dianalange/albums/72157626714986077/)

[More examples here](https://entirelandscapes.space/graphic-notation)

